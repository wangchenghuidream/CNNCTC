{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # CNN+CTC文本识别\n",
    "\n",
    "## 概述\n",
    "\n",
    "文本识别指从图像中识别出文本，将图像中的文字区域转化为字符信息，通常采用CNN网络从图像中提取丰富的特征信息，然后根据提取的特征信息进行识别。这里采用ResNet作为特征提取网络，采用CTC方法进行识别。由于每张样本的字符数量不同，字符样式不同，字体大小也不同，导致每列的输出并不一定能与每个字符一一对应，CTC提出一种不需要对齐的Loss计算方法，用于训练网络。\n",
    "\n",
    "整个模型的文本识别流程如下：\n",
    "1、通过CNN（ResNet）提取文本图片中的Feature map\n",
    "2、对每张图片中的feature map 划分为不同的特征序列（也可使用BiLSTM充分利用上下文信息获取更好的序列，这里为了减少计算复杂度和内存消耗，没有使用BiLSTM）\n",
    "3、对每个序列进行字符分类\n",
    "4、使用Connectionist temporal classification(CTC)损失函数计算loss(输入与标签长度不一致),CTC能够根据固定长度的特征序列预测非固定长度的标签。\n",
    "\n",
    "\n",
    "## Connectionist temporal classfication(CTC)\n",
    "\n",
    "CTC允许预测非固定数量的序列，即使给定了固定数量的特征。CTC的关键方法是预测每列的字符并通过删除重复的字符和空白将整个字符序列修改为非固定的字符流。\n",
    "\n",
    "CTC以序列H = $h_1$, . . . , $h_T$为输入，其中T为序列长度，输出$\\pi$的概率,$\\pi$为预测得到的字符序列，其概率定义为\n",
    "$$p(\\pi|H)=\\prod_{t=1}^{T}{y^t_{\\pi_t}}$$\n",
    "\n",
    ",其中$y^t_{\\pi_t}$为在每个时间步t生成字符$\\pi_t$的概率。\n",
    "\n",
    "然后映射函数M，通过删除重复字符和空白，将$\\pi$映射到Y。\n",
    "例如，对于‘aaa-dd-d-c-d---d’,映射函数M将其映射为‘addcdd’,其中‘-’表示空白。\n",
    "条件概率则定义为由M映射到Y上的所有$\\pi$的概率之和：\n",
    "$$\n",
    "p(Y|H)= \\displaystyle \\sum^{ }_{\\pi:M(\\pi)=Y}{P(\\pi|H)}\n",
    "$$\n",
    "在进行测试的时候，在每个时间步，取具有最大概率的字符，来作为预测的标签序列\n",
    "$$\n",
    "Y^*\\approx M(arg  max  P(\\pi|H))\n",
    "$$\n",
    "\n",
    "## ResNet网络特征提取器\n",
    "\n",
    "残差神经网络(ResNet)是由微软研究院的何恺明、张祥雨、任少卿、孙剑等人提出的。ResNet 在2015 年的ILSVRC（ImageNet Large Scale Visual Recognition Challenge）中取得了冠军。残差神经网络的主要贡献是发现了“退化现象（Degradation）”，并针对退化现象发明了 “快捷连接（Shortcut connection）”，极大的消除了深度过大的神经网络训练困难问题。\n",
    "\n",
    "残差网络结构是ResNet的主要亮点，ResNet使用残差网络结构后可有效地减轻退化问题，实现更深的网络结构设计，提高网络的训练精度\n",
    "\n",
    "###### 构建残差网络结构\n",
    "\n",
    "残差网络结构由两个分支构成：一个主分支，一个shortcuts。主分支通过堆叠一系列卷积操作得到，shortcuts从输入直接到输出，主分支得到的输出加上shortcuts得到的输出，通过Relu激活函数后即为残差网络最后的输出。\n",
    "\n",
    "这里使用的残差网络结构，主分支有两层卷积网络结构：\n",
    "\n",
    "- 第一层网络，kernel_size为3的卷积层 + BatchNorm + Relu\n",
    "- 第二层网络，kernel_size为3的卷积层 + BatchNorm\n",
    "\n",
    "最后将主分支输出的特征矩阵与shortcuts输出的特征矩阵相加，通过Relu激活函数即为残差网络结构的最终输出。\n",
    "\n",
    "###### 构建ResNet网络结构\n",
    "\n",
    "这里的ResNet由5层网络结构组成：\n",
    "\n",
    "- 第一层，kernel_size为3的卷积层 + BatchNorm + kernel_size为3的卷积层 + BatchNorm + Relu\n",
    "- 第二层，最大池化 + 残差网络 + kernel_size为3的卷积层 + BatchNorm\n",
    "- 第三层，最大池化 + 残差网络 + kernel_size为3的卷积层 + BatchNorm\n",
    "- 第四层，最大池化 + 残差网络 + kernel_size为3的卷积层 + BatchNorm\n",
    "- 第五层， 残差网络 + kernel_size为2的卷积层 + BatchNorm + kernel_size为2的卷积层 + BatchNorm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "进行基本的参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding=gbk\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import lmdb\n",
    "import sys\n",
    "import math\n",
    "import six\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import mindspore.common.dtype as mstype\n",
    "from mindspore.ops import operations as P\n",
    "from mindspore.ops import composite as C\n",
    "from mindspore.ops import functional as F\n",
    "from mindspore.common.initializer import TruncatedNormal, initializer\n",
    "from mindspore.common import set_seed\n",
    "from mindspore.communication.management import init, get_rank, get_group_size\n",
    "from mindspore.dataset import GeneratorDataset\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, TimeMonitor, Callback\n",
    "from mindspore.train.model import Model\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "from mindspore import Tensor, Parameter, ParameterTuple, context\n",
    "from mindspore.context import ParallelMode\n",
    "from mindspore.nn.wrap.grad_reducer import DistributedGradReducer\n",
    "\n",
    "parser = argparse.ArgumentParser(description='default name', add_help=False)\n",
    "parser.add_argument('--device_target', type=str, default='GPU', help='NPU\\GPU\\CPU')\n",
    "parser.add_argument('--CHARACTER', type=str, default=\"0123456789abcdefghijklmnopqrstuvwxyz\", help=' ')\n",
    "parser.add_argument('--NUM_CLASS', type=int, default=37, help=' ')\n",
    "parser.add_argument('--HIDDEN_SIZE', type=int, default=512, help=' ')\n",
    "parser.add_argument('--FINAL_FEATURE_WIDTH', type=int, default=26, help=' ')\n",
    "parser.add_argument('--IMG_H', type=int, default=32, help=' ')\n",
    "parser.add_argument('--IMG_W', type=int, default=100, help=' ')\n",
    "parser.add_argument('--TRAIN_BATCH_SIZE', type=int, default=64, help=' ')\n",
    "parser.add_argument('--TEST_BATCH_SIZE', type=int, default=64, help=' ')\n",
    "parser.add_argument('--TRAIN_EPOCHS', type=int, default=3, help=' ')\n",
    "parser.add_argument('--TRAIN_DATASET_PATH', type=str, default=\"ST_MJ/\", help=' ')\n",
    "parser.add_argument('--TRAIN_DATASET_INDEX_PATH', type=str, default=\"st_mj_fixed_length_index_list.pkl\", help=' ')\n",
    "parser.add_argument('--TEST_DATASET_PATH', type=str, default=\"cnnctc_data/IIIT/\", help=' ')\n",
    "parser.add_argument('--CHECKPOINT_PATH', type=str, default=\"/home/wch/cnnctc_wch/ckpt_gpu_1p/CNNCTC-3_650.ckpt\", help=' ')\n",
    "parser.add_argument('--PRED_TRAINED', type=str, default='', help='pred training')\n",
    "parser.add_argument('--SAVE_PATH', type=str, default='', help='saving the ckpl')\n",
    "parser.add_argument('--run_distribute', type=bool, default=False, help=' ')\n",
    "parser.add_argument('--base_lr', type=float, default=0.0005, help=' ')\n",
    "parser.add_argument('--warmup_ratio', type=float, default=0.0625, help=' ')\n",
    "parser.add_argument('--MOMENTUM', type=float, default=0.8, help=' ')\n",
    "parser.add_argument('--warmup_step', type=int, default=2000, help=' ')\n",
    "parser.add_argument('--LOSS_SCALE', type=int, default=8096, help=' ')\n",
    "parser.add_argument('--SAVE_CKPT_PER_N_STEP', type=int, default=1000, help=' ')\n",
    "parser.add_argument('--KEEP_CKPT_MAX_NUM', type=int, default=5, help=' ')\n",
    "\n",
    "config = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了使得训练的结果更具有说明性，采用了多个数据集进行训练，在训练之前需要将多个数据集合并为一个数据集；同时数据集中每条数据的标签长度不一，为了达到更好的训练效果，希望每次训练的数据的标签长度都一致，在提取数据的时候需要按照一定的索引进行提取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将MJSynth和SynthText数据集组合为一个lmdb文件\n",
    "def combine_lmdbs(lmdb_paths, lmdb_save_path):\n",
    "    max_len = int((26 + 1) // 2)\n",
    "    character = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "    env_save = lmdb.open(lmdb_save_path,map_size=1099511627776)\n",
    "    cnt = 0\n",
    "    for lmdb_path in lmdb_paths:\n",
    "        env = lmdb.open(lmdb_path, max_readers=32, readonly=True, lock=False, readahead=False, meminit=False)\n",
    "        with env.begin(write=False) as txn:\n",
    "            nSamples = int(txn.get('num-samples'.encode()))\n",
    "            nSamples = nSamples\n",
    "            # Filtering\n",
    "            for index in tqdm(range(nSamples)):\n",
    "                index += 1  # lmdb starts with 1\n",
    "                label_key = 'label-%09d'.encode() % index\n",
    "                label = txn.get(label_key).decode('utf-8')\n",
    "                if len(label) > max_len:\n",
    "                    continue\n",
    "                illegal_sample = False\n",
    "                for char_item in label.lower():\n",
    "                    if char_item not in character:\n",
    "                        illegal_sample = True\n",
    "                        break\n",
    "                if illegal_sample:\n",
    "                    continue\n",
    "                img_key = 'image-%09d'.encode() % index\n",
    "                imgbuf = txn.get(img_key)\n",
    "                with env_save.begin(write=True) as txn_save:\n",
    "                    cnt += 1\n",
    "                    label_key_save = 'label-%09d'.encode() % cnt\n",
    "                    label_save = label.encode()\n",
    "                    image_key_save = 'image-%09d'.encode() % cnt\n",
    "                    image_save = imgbuf\n",
    "                    txn_save.put(label_key_save, label_save)\n",
    "                    txn_save.put(image_key_save, image_save)\n",
    "    nSamples = cnt\n",
    "    with env_save.begin(write=True) as txn_save:\n",
    "        txn_save.put('num-samples'.encode(), str(nSamples).encode())\n",
    "        \n",
    "#在一个batch中所有数据的label总长度固定的情况下，batch中组成数据的label的长度的可能组合\n",
    "#首先得到每条数据中标签的长度，获取数据集中各种标签长度的分布情况，以及数据集中所有标签的总长度\n",
    "#获取每个batch中的平均长度\n",
    "#根据batch中的平均长度以及各种标签长度的分布情况，获得可能的组合，使得每个batch的平均长度相同\n",
    "def analyze_lmdb_label_length(lmdb_path, batch_size=64, num_of_combinations=1000):\n",
    "    label_length_dict = {}\n",
    "\n",
    "    env = lmdb.open(lmdb_path, max_readers=32, readonly=True, lock=False, readahead=False, meminit=False)\n",
    "    with env.begin(write=False) as txn:\n",
    "        nSamples = int(txn.get('num-samples'.encode()))\n",
    "        nSamples = nSamples\n",
    "\n",
    "        for index in tqdm(range(nSamples)):\n",
    "            index += 1  # lmdb starts with 1\n",
    "            label_key = 'label-%09d'.encode() % index\n",
    "            label = txn.get(label_key).decode('utf-8')\n",
    "\n",
    "            label_length = len(label)\n",
    "            if label_length in label_length_dict:\n",
    "                label_length_dict[label_length] += 1\n",
    "            else:\n",
    "                label_length_dict[label_length] = 1\n",
    "\n",
    "    sorted_label_length = sorted(label_length_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    label_length_sum = 0\n",
    "    label_num = 0\n",
    "    lengths = []\n",
    "    p = []\n",
    "    for l, num in sorted_label_length:\n",
    "        label_length_sum += l * num\n",
    "        label_num += num\n",
    "        p.append(num)\n",
    "        lengths.append(l)\n",
    "    for i, _ in enumerate(p):\n",
    "        p[i] /= label_num\n",
    "\n",
    "    average_overall_length = int(label_length_sum / label_num * batch_size)\n",
    "\n",
    "    def get_combinations_of_fix_length(fix_length, items, p, batch_size):\n",
    "        ret = []\n",
    "        cur_sum = 0\n",
    "        ret = np.random.choice(items, batch_size - 1, True, p)\n",
    "        cur_sum = sum(ret)\n",
    "        ret = list(ret)\n",
    "        if fix_length - cur_sum in items:\n",
    "            ret.append(fix_length - cur_sum)\n",
    "        else:\n",
    "            return None\n",
    "        return ret\n",
    "\n",
    "    result = []\n",
    "    while len(result) < num_of_combinations:\n",
    "        ret = get_combinations_of_fix_length(average_overall_length, lengths, p, batch_size)\n",
    "        if ret is not None:\n",
    "            result.append(ret)\n",
    "    return result\n",
    "\n",
    "#根据获取的可能组合，形成训练时采集数据的索引列表\n",
    "#注意：这里的num_of_iters应该根据实际训练数据集的大小进行适当调整\n",
    "#在采样过程中，是根据标签长度组合随机选择的，故num_of_iters应该设置稍微大一点，才能基本将数据集中所有数据都采集一遍\n",
    "def generate_fix_shape_index_list(lmdb_path, combinations, pkl_save_path, num_of_iters=650):\n",
    "    length_index_dict = {}\n",
    "\n",
    "    env = lmdb.open(lmdb_path, max_readers=32, readonly=True, lock=False, readahead=False, meminit=False)\n",
    "    with env.begin(write=False) as txn:\n",
    "        nSamples = int(txn.get('num-samples'.encode()))\n",
    "        nSamples = nSamples\n",
    "\n",
    "        for index in tqdm(range(nSamples)):\n",
    "            index += 1  # lmdb starts with 1\n",
    "            label_key = 'label-%09d'.encode() % index\n",
    "            label = txn.get(label_key).decode('utf-8')\n",
    "\n",
    "            label_length = len(label)\n",
    "            if label_length in length_index_dict:\n",
    "                length_index_dict[label_length].append(index)\n",
    "            else:\n",
    "                length_index_dict[label_length] = [index]\n",
    "\n",
    "    ret = []\n",
    "    for _ in range(num_of_iters):\n",
    "        comb = random.choice(combinations)\n",
    "        for l in comb:\n",
    "            ret.append(random.choice(length_index_dict[l]))\n",
    "\n",
    "    with open(pkl_save_path, 'wb') as f:\n",
    "        pickle.dump(ret, f, -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络设计\n",
    "特征提取器采用ResNet网络进行提取，预测器使用线性网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNCTC_Model(nn.Cell):\n",
    "\n",
    "    def __init__(self, num_class, hidden_size, final_feature_width):\n",
    "        super(CNNCTC_Model, self).__init__()\n",
    "\n",
    "        self.num_class = num_class\n",
    "        self.hidden_size = hidden_size\n",
    "        self.final_feature_width = final_feature_width\n",
    "\n",
    "        self.FeatureExtraction = ResNet(3, 512, BasicBlock, [1, 2, 5, 3])\n",
    "        self.Prediction = nn.Dense(self.hidden_size, self.num_class)\n",
    "\n",
    "        self.transpose = P.Transpose()\n",
    "        self.reshape = P.Reshape()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.FeatureExtraction(x)\n",
    "        x = self.transpose(x, (0, 3, 1, 2))  # [b, c, h, w] -> [b, w, c, h]\n",
    "\n",
    "        x = self.reshape(x, (-1, self.hidden_size))\n",
    "        x = self.Prediction(x)\n",
    "        x = self.reshape(x, (-1, self.final_feature_width, self.num_class))\n",
    "\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Cell):\n",
    "    def __init__(self, input_channel, output_channel, block, layers):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.output_channel_block = [int(output_channel / 4), int(output_channel / 2), output_channel, output_channel]\n",
    "        self.inplanes = int(output_channel / 8)\n",
    "        \n",
    "        self.conv0_1 = nn.Conv2d(input_channel, int(output_channel / 16), kernel_size=3, stride=1, padding=1, pad_mode='pad', weight_init=TruncatedNormal(0.02), has_bias=False)        \n",
    "        self.bn0_1 = nn.BatchNorm2d(int(output_channel / 16), momentum=0.1)\n",
    "        self.conv0_2 = nn.Conv2d(int(output_channel / 16), self.inplanes, kernel_size=3, stride=1, padding=1, pad_mode='pad', weight_init=TruncatedNormal(0.02), has_bias=False)\n",
    "        self.bn0_2 = nn.BatchNorm2d(self.inplanes, momentum=0.1)\n",
    "        self.relu = P.ReLU()\n",
    "\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, pad_mode='valid')\n",
    "        self.layer1 = self._make_layer(block, self.output_channel_block[0], layers[0])\n",
    "        self.conv1 = nn.Conv2d(self.output_channel_block[0], self.output_channel_block[0], kernel_size=3, stride=1, padding=1, pad_mode='pad', weight_init=TruncatedNormal(0.02), has_bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.output_channel_block[0], momentum=0.1)\n",
    "        \n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2, pad_mode='valid')\n",
    "        self.layer2 = self._make_layer(block, self.output_channel_block[1], layers[1])\n",
    "        self.conv2 =  nn.Conv2d(self.output_channel_block[1], self.output_channel_block[1], kernel_size=3, stride=1, padding=1, pad_mode='pad', weight_init=TruncatedNormal(0.02), has_bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.output_channel_block[1], momentum=0.1)\n",
    "        self.pad = P.Pad(((0, 0), (0, 0), (0, 0), (2, 2)))\n",
    "        \n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=(2, 1), pad_mode='valid')\n",
    "        self.layer3 = self._make_layer(block, self.output_channel_block[2], layers[2])     \n",
    "        self.conv3 = nn.Conv2d(self.output_channel_block[2], self.output_channel_block[2], kernel_size=3, stride=1, padding=1, pad_mode='pad', weight_init=TruncatedNormal(0.02), has_bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.output_channel_block[2], momentum=0.1)\n",
    "        \n",
    "        self.layer4 = self._make_layer(block, self.output_channel_block[3], layers[3])    \n",
    "        self.conv4_1 = nn.Conv2d(self.output_channel_block[3], self.output_channel_block[3], kernel_size=2, stride=(2, 1), padding=0, pad_mode='valid', weight_init=TruncatedNormal(0.02), has_bias=False)\n",
    "        self.bn4_1 = nn.BatchNorm2d(self.output_channel_block[3], momentum=0.1)        \n",
    "        self.conv4_2 = nn.Conv2d(self.output_channel_block[3], self.output_channel_block[3], kernel_size=2, stride=1, padding=0, pad_mode='valid', weight_init=TruncatedNormal(0.02), has_bias=False)\n",
    "        self.bn4_2 = nn.BatchNorm2d(self.output_channel_block[3], momentum=0.1)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.SequentialCell(\n",
    "                [nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, padding=0, pad_mode='same', weight_init=TruncatedNormal(0.02), has_bias=False),\n",
    "                 nn.BatchNorm2d(planes * block.expansion, momentum=0.1)]\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv0_1(x)\n",
    "        x = self.bn0_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv0_2(x)\n",
    "        x = self.bn0_2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "        x = self.pad(x)\n",
    "        x = self.conv4_1(x)\n",
    "        x = self.bn4_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv4_2(x)\n",
    "        x = self.bn4_2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class BasicBlock(nn.Cell):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, pad_mode='pad', weight_init=TruncatedNormal(0.02), has_bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=0.1)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, pad_mode='pad', weight_init=TruncatedNormal(0.02), has_bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=0.1)\n",
    "        self.relu = P.ReLU()\n",
    "        self.downsample = downsample\n",
    "        self.add = P.Add()\n",
    "\n",
    "    def construct(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out = self.add(out, residual)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集封装\n",
    "从数据集中按索引提取数据时，需要对图片数据进行一定的处理，包括归一化处理，图片转tensor，文本标签到索引标签之间的转换，按长度分组索引提取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#从lmdb文件中读取图片和标签\n",
    "def get_img_from_lmdb(env, index):\n",
    "    with env.begin(write=False) as txn:\n",
    "        label_key = 'label-%09d'.encode() % index\n",
    "        label = txn.get(label_key).decode('utf-8')\n",
    "        img_key = 'image-%09d'.encode() % index\n",
    "        imgbuf = txn.get(img_key)\n",
    "\n",
    "        buf = six.BytesIO()\n",
    "        buf.write(imgbuf)\n",
    "        buf.seek(0)\n",
    "        try:\n",
    "            img = Image.open(buf).convert('RGB')  # for color image\n",
    "\n",
    "        except IOError:\n",
    "            print(f'Corrupted image for {index}')\n",
    "            # make dummy image and dummy label for corrupted image.\n",
    "            img = Image.new('RGB', (config.IMG_W, config.IMG_H))\n",
    "            label = '[dummy_label]'\n",
    "\n",
    "    label = label.lower()\n",
    "\n",
    "    return img, label\n",
    "\n",
    "#对图片进行归一化\n",
    "class NormalizePAD():\n",
    "\n",
    "    def __init__(self, max_size, PAD_type='right'):\n",
    "        self.max_size = max_size\n",
    "        self.PAD_type = PAD_type\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # toTensor\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        # normalize\n",
    "        means = [121.58949, 123.93914, 123.418655]\n",
    "        stds = [65.70353, 65.142426, 68.61079]\n",
    "        img = np.subtract(img, means)\n",
    "        img = np.true_divide(img, stds)\n",
    "\n",
    "        img = img.transpose([2, 0, 1])\n",
    "        img = img.astype(float)\n",
    "\n",
    "        _, _, w = img.shape\n",
    "        Pad_img = np.zeros(shape=self.max_size, dtype=np.float32)\n",
    "        Pad_img[:, :, :w] = img  # right pad\n",
    "        if self.max_size[2] != w:  # add border Pad\n",
    "            Pad_img[:, :, w:] = np.tile(np.expand_dims(img[:, :, w - 1], 2), (1, 1, self.max_size[2] - w))\n",
    "\n",
    "        return Pad_img\n",
    "    \n",
    "#图片resize后转为统一shape的tensor\n",
    "class AlignCollate():\n",
    "\n",
    "    def __init__(self, imgH=32, imgW=100):\n",
    "        self.imgH = imgH\n",
    "        self.imgW = imgW\n",
    "\n",
    "    def __call__(self, images):\n",
    "\n",
    "        resized_max_w = self.imgW\n",
    "        input_channel = 3\n",
    "        transform = NormalizePAD((input_channel, self.imgH, resized_max_w))\n",
    "\n",
    "        resized_images = []\n",
    "        for image in images:\n",
    "            w, h = image.size\n",
    "            ratio = w / float(h)\n",
    "            if math.ceil(self.imgH * ratio) > self.imgW:\n",
    "                resized_w = self.imgW\n",
    "            else:\n",
    "                resized_w = math.ceil(self.imgH * ratio)\n",
    "\n",
    "            resized_image = image.resize((resized_w, self.imgH), Image.BICUBIC)\n",
    "            resized_images.append(transform(resized_image))\n",
    "\n",
    "        image_tensors = np.concatenate([np.expand_dims(t, 0) for t in resized_images], 0)\n",
    "\n",
    "        return image_tensors\n",
    "\n",
    "    \n",
    "#文本标签到索引标签之间的转换\n",
    "#将文本转换为数字编码\n",
    "#CHARACTER: \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "#则‘hate’----->[18,11,30,15]\n",
    "class CTCLabelConverter():\n",
    "    \"\"\" Convert between text-label and text-index \"\"\"\n",
    "\n",
    "    def __init__(self, character):\n",
    "        # character (str): set of the possible characters.\n",
    "        dict_character = list(character)\n",
    "\n",
    "        self.dict = {}\n",
    "        for i, char in enumerate(dict_character):\n",
    "            self.dict[char] = i\n",
    "\n",
    "        self.character = dict_character + ['[blank]']  # dummy '[blank]' token for CTCLoss (index 0)\n",
    "        self.dict['[blank]'] = len(dict_character)\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"convert text-label into text-index.\n",
    "        input:\n",
    "            text: text labels of each image. [batch_size]\n",
    "\n",
    "        output:\n",
    "            text: concatenated text index for CTCLoss.\n",
    "                    [sum(text_lengths)] = [text_index_0 + text_index_1 + ... + text_index_(n - 1)]\n",
    "            length: length of each text. [batch_size]\n",
    "        \"\"\"\n",
    "        length = [len(s) for s in text]\n",
    "        text = ''.join(text)\n",
    "        text = [self.dict[char] for char in text]\n",
    "\n",
    "        return np.array(text), np.array(length)\n",
    "\n",
    "    def decode(self, text_index, length):\n",
    "        \"\"\" convert text-index into text-label. \"\"\"\n",
    "        texts = []\n",
    "        index = 0\n",
    "        for l in length:\n",
    "            t = text_index[index:index + l]\n",
    "\n",
    "            char_list = []\n",
    "            for i in range(l):\n",
    "                # if t[i] != self.dict['[blank]'] and (not (i > 0 and t[i - 1] == t[i])):  # removing repeated characters and blank.\n",
    "                if t[i] != self.dict['[blank]'] and (\n",
    "                        not (i > 0 and t[i - 1] == t[i])):  # removing repeated characters and blank.\n",
    "                    char_list.append(self.character[t[i]])\n",
    "            text = ''.join(char_list)\n",
    "\n",
    "            texts.append(text)\n",
    "            index += l\n",
    "        return texts\n",
    "\n",
    "    def reverse_encode(self, text_index, length):\n",
    "        \"\"\" convert text-index into text-label. \"\"\"\n",
    "        texts = []\n",
    "        index = 0\n",
    "        for l in length:\n",
    "            t = text_index[index:index + l]\n",
    "\n",
    "            char_list = []\n",
    "            for i in range(l):\n",
    "                if t[i] != self.dict['[blank]']:  # removing repeated characters and blank.\n",
    "                    char_list.append(self.character[t[i]])\n",
    "            text = ''.join(char_list)\n",
    "\n",
    "            texts.append(text)\n",
    "            index += l\n",
    "        return texts\n",
    "\n",
    "#训练数据集封装\n",
    "class ST_MJ_Generator_batch_fixed_length:\n",
    "    def __init__(self):\n",
    "        self.align_collector = AlignCollate()\n",
    "        self.converter = CTCLabelConverter(config.CHARACTER)\n",
    "        self.env = lmdb.open(config.TRAIN_DATASET_PATH, max_readers=32, readonly=True, lock=False, readahead=False,\n",
    "                             meminit=False)\n",
    "        if not self.env:\n",
    "            print('cannot create lmdb from %s' % (config.TRAIN_DATASET_PATH))\n",
    "            raise ValueError(config.TRAIN_DATASET_PATH)\n",
    "\n",
    "        with open(config.TRAIN_DATASET_INDEX_PATH, 'rb') as f:\n",
    "            self.st_mj_filtered_index_list = pickle.load(f)\n",
    "\n",
    "        print(f'num of samples in ST_MJ dataset: {len(self.st_mj_filtered_index_list)}')\n",
    "        \n",
    "        \n",
    "        if config.run_distribute:\n",
    "            self.rank_id = get_rank()\n",
    "            self.rank_size = get_group_size()\n",
    "            self.dataset_size = len(self.st_mj_filtered_index_list) // config.TRAIN_BATCH_SIZE // self.rank_size\n",
    "        else:\n",
    "            self.dataset_size = len(self.st_mj_filtered_index_list) // config.TRAIN_BATCH_SIZE\n",
    "        self.batch_size = config.TRAIN_BATCH_SIZE\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_ret = []\n",
    "        text_ret = []\n",
    "        \n",
    "        if config.run_distribute:\n",
    "            rank_item = (item * self.rank_size) + self.rank_id\n",
    "        else:\n",
    "            rank_item = item\n",
    "        for i in range(rank_item * self.batch_size, (rank_item + 1) * self.batch_size):\n",
    "            index = self.st_mj_filtered_index_list[i]\n",
    "            img, label = get_img_from_lmdb(self.env, index)\n",
    "\n",
    "            img_ret.append(img)\n",
    "            text_ret.append(label)\n",
    "\n",
    "        img_ret = self.align_collector(img_ret)\n",
    "        text_ret, length = self.converter.encode(text_ret)\n",
    "\n",
    "        label_indices = []\n",
    "        for i, _ in enumerate(length):\n",
    "            for j in range(length[i]):\n",
    "                label_indices.append((i, j))\n",
    "        label_indices = np.array(label_indices, np.int64)\n",
    "        sequence_length = np.array([config.FINAL_FEATURE_WIDTH] * config.TRAIN_BATCH_SIZE, dtype=np.int32)\n",
    "        text_ret = text_ret.astype(np.int32)\n",
    "\n",
    "        return img_ret, label_indices, text_ret, sequence_length\n",
    "\n",
    "    \n",
    "#对于验证数据集就无需使得提取的数据的标签具有相同的长度\n",
    "#验证数据集封装\n",
    "def IIIT_Generator_batch():\n",
    "    max_len = int((26 + 1) // 2)\n",
    "\n",
    "    align_collector = AlignCollate()\n",
    "\n",
    "    converter = CTCLabelConverter(config.CHARACTER)\n",
    "\n",
    "    env = lmdb.open(config.TEST_DATASET_PATH, max_readers=32, readonly=True, lock=False, readahead=False, meminit=False)\n",
    "    if not env:\n",
    "        print('cannot create lmdb from %s' % (config.TEST_DATASET_PATH))\n",
    "        sys.exit(0)\n",
    "\n",
    "    with env.begin(write=False) as txn:\n",
    "        nSamples = int(txn.get('num-samples'.encode()))\n",
    "        nSamples = nSamples\n",
    "\n",
    "        # Filtering\n",
    "        filtered_index_list = []\n",
    "        for index in range(nSamples):\n",
    "            index += 1  # lmdb starts with 1\n",
    "            label_key = 'label-%09d'.encode() % index\n",
    "            label = txn.get(label_key).decode('utf-8')\n",
    "\n",
    "            if len(label) > max_len:\n",
    "                continue\n",
    "\n",
    "            illegal_sample = False\n",
    "            for char_item in label.lower():\n",
    "                if char_item not in config.CHARACTER:\n",
    "                    illegal_sample = True\n",
    "                    break\n",
    "            if illegal_sample:\n",
    "                continue\n",
    "\n",
    "            filtered_index_list.append(index)\n",
    "\n",
    "    img_ret = []\n",
    "    text_ret = []\n",
    "\n",
    "    print(f'num of samples in IIIT dataset: {len(filtered_index_list)}')\n",
    "\n",
    "    for index in filtered_index_list:\n",
    "\n",
    "        img, label = get_img_from_lmdb(env, index)\n",
    "\n",
    "        img_ret.append(img)\n",
    "        text_ret.append(label)\n",
    "\n",
    "        if len(img_ret) == config.TEST_BATCH_SIZE:\n",
    "            img_ret = align_collector(img_ret)\n",
    "            text_ret, length = converter.encode(text_ret)\n",
    "\n",
    "            label_indices = []\n",
    "            for i, _ in enumerate(length):\n",
    "                for j in range(length[i]):\n",
    "                    label_indices.append((i, j))\n",
    "            label_indices = np.array(label_indices, np.int64)\n",
    "            sequence_length = np.array([26] * config.TEST_BATCH_SIZE, dtype=np.int32)\n",
    "            text_ret = text_ret.astype(np.int32)\n",
    "\n",
    "            yield img_ret, label_indices, text_ret, sequence_length, length\n",
    "\n",
    "            img_ret = []\n",
    "            text_ret = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数设计\n",
    "这里采用mindspore已经实现的CTCloss函数接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#loss设计\n",
    "class ctc_loss(nn.Cell):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ctc_loss, self).__init__()\n",
    "\n",
    "        self.loss = P.CTCLoss(preprocess_collapse_repeated=False,\n",
    "                              ctc_merge_repeated=True,\n",
    "                              ignore_longer_outputs_than_inputs=False)\n",
    "\n",
    "        self.mean = P.ReduceMean()\n",
    "        self.transpose = P.Transpose()\n",
    "        self.reshape = P.Reshape()\n",
    "\n",
    "    def construct(self, inputs, labels_indices, labels_values, sequence_length):\n",
    "        inputs = self.transpose(inputs, (1, 0, 2))\n",
    "\n",
    "        loss, _ = self.loss(inputs, labels_indices, labels_values, sequence_length)\n",
    "\n",
    "        loss = self.mean(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习率列表\n",
    "根据训练的总的step数，设置学习率\n",
    "在warmup_steps以内的step，学习率线性改变\n",
    "在warmup_steps之后的step,学习率改变符合余弦分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dynamic_lr(config, steps_per_epoch):\n",
    "    \"\"\"dynamic learning rate generator\"\"\"\n",
    "    base_lr = config.base_lr\n",
    "    total_steps = steps_per_epoch * config.TRAIN_EPOCHS\n",
    "    warmup_steps = int(config.warmup_step)\n",
    "    decay_steps = total_steps - warmup_steps\n",
    "    lr = []\n",
    "    for i in range(total_steps):\n",
    "        if i < warmup_steps:\n",
    "            lr_inc = (float(base_lr) - float(base_lr * config.warmup_ratio)) / float(warmup_steps)\n",
    "            learning_rate = float(base_lr * config.warmup_ratio) + lr_inc * i\n",
    "            lr.append(learning_rate)\n",
    "        else:\n",
    "            base = float(i - warmup_steps) / float(decay_steps)\n",
    "            learning_rate = (1 + math.cos(base * math.pi)) / 2 * base_lr    \n",
    "            lr.append(learning_rate )\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在GPU训练中，为处理梯度溢出的现象，将梯度裁剪和模型训练进行组合封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#封装model与loss函数\n",
    "class WithLossCell(nn.Cell):\n",
    "\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        super(WithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "\n",
    "    def construct(self, img, label_indices, text, sequence_length):\n",
    "        model_predict = self._backbone(img)\n",
    "        return self._loss_fn(model_predict, label_indices, text, sequence_length)\n",
    "\n",
    "    @property\n",
    "    def backbone_network(self):\n",
    "        return self._backbone\n",
    "    \n",
    "#梯度裁剪，使用L2范数控制梯度\n",
    "class ClipGradients(nn.Cell):\n",
    "    \"\"\"\n",
    "    Clip large gradients, typically generated from overflow.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ClipGradients, self).__init__()\n",
    "        self.clip_by_norm = nn.ClipByNorm()\n",
    "        self.cast = P.Cast()\n",
    "        self.dtype = P.DType()\n",
    "    def construct(self, grads, clip_min, clip_max):\n",
    "        new_grads = ()\n",
    "        for grad in grads:\n",
    "            dt = self.dtype(grad)\n",
    "\n",
    "            t = C.clip_by_value(grad, self.cast(F.tuple_to_array((clip_min,)), dt),\n",
    "                                self.cast(F.tuple_to_array((clip_max,)), dt))\n",
    "            t = self.cast(t, dt)\n",
    "            new_grads = new_grads + (t,)\n",
    "        return new_grads\n",
    "\n",
    "    \n",
    "grad_scale = C.MultitypeFuncGraph(\"grad_scale\")\n",
    "reciprocal = P.Reciprocal()\n",
    "GRADIENT_CLIP_MIN = -64000\n",
    "GRADIENT_CLIP_MAX = 64000\n",
    "\n",
    "\n",
    "@grad_scale.register(\"Tensor\", \"Tensor\")\n",
    "def tensor_grad_scale(scale, grad):\n",
    "    return grad * F.cast(reciprocal(scale), F.dtype(grad))\n",
    "\n",
    "class CNNCTCTrainOneStepWithLossScaleCell(nn.Cell):\n",
    "    \"\"\"\n",
    "    Encapsulation class of CNNCTC network training.\n",
    "    Used for GPU training in order to manage overflowing gradients.\n",
    "    Args:\n",
    "        network (Cell): The training network. Note that loss function should have been added.\n",
    "        optimizer (Optimizer): Optimizer for updating the weights.\n",
    "        scale_sense (Cell): Loss scaling value.\n",
    "    \"\"\"\n",
    "    def __init__(self, network, optimizer, scale_sense):\n",
    "        super(CNNCTCTrainOneStepWithLossScaleCell, self).__init__(auto_prefix=False)\n",
    "        self.network = network\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if isinstance(scale_sense, nn.Cell):\n",
    "            self.loss_scaling_manager = scale_sense\n",
    "            self.scale_sense = Parameter(Tensor(scale_sense.get_loss_scale(),\n",
    "                                                dtype=mstype.float32), name=\"scale_sense\")\n",
    "        elif isinstance(scale_sense, Tensor):\n",
    "            if scale_sense.shape == (1,) or scale_sense.shape == ():\n",
    "                self.scale_sense = Parameter(scale_sense, name='scale_sense')\n",
    "            else:\n",
    "                raise ValueError(\"The shape of scale_sense must be (1,) or (), but got {}\".format(\n",
    "                    scale_sense.shape))\n",
    "        else:\n",
    "            raise TypeError(\"The scale_sense must be Cell or Tensor, but got {}\".format(\n",
    "                type(scale_sense)))\n",
    "\n",
    "        self.network.set_grad()\n",
    "        self.weights = ParameterTuple(network.trainable_params())\n",
    "\n",
    "        self.grad = C.GradOperation(get_by_list=True,\n",
    "                                    sens_param=True)\n",
    "\n",
    "        self.reducer_flag = False\n",
    "        self.parallel_mode = context.get_auto_parallel_context(\"parallel_mode\")\n",
    "        if self.parallel_mode not in ParallelMode.MODE_LIST:\n",
    "            raise ValueError(\"Parallel mode does not support: \", self.parallel_mode)\n",
    "        if self.parallel_mode in [ParallelMode.DATA_PARALLEL, ParallelMode.HYBRID_PARALLEL]:\n",
    "            self.reducer_flag = True\n",
    "        self.grad_reducer = None\n",
    "        if self.reducer_flag:\n",
    "            mean = context.get_auto_parallel_context(\"gradients_mean\")\n",
    "            degree = get_group_size()\n",
    "            self.grad_reducer = DistributedGradReducer(optimizer.parameters, mean, degree)\n",
    "        self.is_distributed = (self.parallel_mode != ParallelMode.STAND_ALONE)\n",
    "\n",
    "        self.clip_gradients = ClipGradients()\n",
    "        self.cast = P.Cast()\n",
    "        self.addn = P.AddN()\n",
    "        self.reshape = P.Reshape()\n",
    "        self.hyper_map = C.HyperMap()\n",
    "        self.less_equal = P.LessEqual()\n",
    "        self.allreduce = P.AllReduce()\n",
    "        #grad_scale = C.MultitypeFuncGraph(\"grad_scale\")\n",
    "#reciprocal = P.Reciprocal()\n",
    "    def construct(self, img, label_indices, text, sequence_length):\n",
    "        weights = self.weights\n",
    "        loss = self.network(img, label_indices, text, sequence_length)\n",
    "\n",
    "        scaling_sens = self.scale_sense\n",
    "\n",
    "        grads = self.grad(self.network, weights)(img, label_indices, text, sequence_length,\n",
    "                                                 self.cast(scaling_sens, mstype.float32))\n",
    "        grads = self.hyper_map(F.partial(grad_scale, scaling_sens), grads)\n",
    "        grads = self.clip_gradients(grads, -64000, 64000)\n",
    "\n",
    "        if self.reducer_flag:\n",
    "            #apply grad reducer on grads\n",
    "            grads = self.grad_reducer(grads)\n",
    "\n",
    "        self.optimizer(grads)\n",
    "        return (loss, scaling_sens)\n",
    "    \n",
    "class AverageMeter():\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "#自定义loss回调函数\n",
    "class LossCallBack(Callback):\n",
    "    \"\"\"\n",
    "    Monitor the loss in training.\n",
    "\n",
    "    If the loss is NAN or INF terminating training.\n",
    "\n",
    "    Note:\n",
    "        If per_print_times is 0 do not print loss.\n",
    "\n",
    "    Args:\n",
    "        per_print_times (int): Print loss every times. Default: 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, per_print_times=1):\n",
    "        super(LossCallBack, self).__init__()\n",
    "        if not isinstance(per_print_times, int) or per_print_times < 0:\n",
    "            raise ValueError(\"print_step must be int and >= 0.\")\n",
    "        self._per_print_times = per_print_times\n",
    "        self.loss_avg = AverageMeter()\n",
    "        self.timer = AverageMeter()\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def step_end(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "\n",
    "        loss = np.array(cb_params.net_outputs)\n",
    "\n",
    "        cur_step_in_epoch = (cb_params.cur_step_num - 1) % cb_params.batch_num + 1\n",
    "        cur_num = cb_params.cur_step_num\n",
    "\n",
    "        if cur_step_in_epoch % 2000 == 1:\n",
    "            self.loss_avg = AverageMeter()\n",
    "            self.timer = AverageMeter()\n",
    "            self.start_time = time.time()\n",
    "        else:\n",
    "            self.timer.update(time.time() - self.start_time)\n",
    "            self.start_time = time.time()\n",
    "\n",
    "        self.loss_avg.update(loss)\n",
    "\n",
    "        if self._per_print_times != 0 and cur_num % self._per_print_times == 0:\n",
    "            loss_file = open(\"./loss.log\", \"a+\")\n",
    "            loss_file.write(\"epoch: %d step: %d , loss is %s\" % (\n",
    "                cb_params.cur_epoch_num, cur_step_in_epoch,\n",
    "                self.loss_avg.avg))\n",
    "            loss_file.write(\"\\n\")\n",
    "            loss_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义训练和验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train过程\n",
    "def train():\n",
    "    target = config.device_target\n",
    "    mindspore.set_context(device_target=target)\n",
    "    \n",
    "    if target == \"Ascend\":\n",
    "        device_id = int(os.getenv('DEVICE_ID', '0'))\n",
    "        mindspore.set_context(device_id=device_id)\n",
    "        if config.run_distribute:\n",
    "            init()\n",
    "            context.set_auto_parallel_context(parallel_mode=\"data_parallel\")\n",
    "        ckpt_save_dir = config.SAVE_PATH\n",
    "    else:\n",
    "        device_id = int(os.getenv('DEVICE_ID', '0'))\n",
    "        mindspore.set_context(device_id=device_id)\n",
    "        if config.run_distribute:\n",
    "            init()\n",
    "            context.set_auto_parallel_context(device_num=get_group_size(), parallel_mode=\"data_parallel\", gradients_mean=False, gradient_fp32_sync=False)\n",
    "            ckpt_save_dir = config.SAVE_PATH + \"ckpt_\" + str(get_rank()) + \"/\"\n",
    "            print(ckpt_save_dir)\n",
    "        else:\n",
    "            ckpt_save_dir = config.SAVE_PATH + \"ckpt_gpu_1p/\"\n",
    "            \n",
    "    st_dataset = ST_MJ_Generator_batch_fixed_length()\n",
    "    ds = GeneratorDataset(st_dataset, ['img', 'label_indices', 'text', 'sequence_length'], num_parallel_workers=4)\n",
    "    net = CNNCTC_Model(config.NUM_CLASS, config.HIDDEN_SIZE, config.FINAL_FEATURE_WIDTH)\n",
    "    net.set_train(True)\n",
    "\n",
    "    if config.PRED_TRAINED:\n",
    "        param_dict = load_checkpoint(config.PRED_TRAINED)\n",
    "        load_param_into_net(net, param_dict)\n",
    "        print('parameters loaded!')\n",
    "    else:\n",
    "        print('train from scratch...')\n",
    "\n",
    "    criterion = ctc_loss()\n",
    "    print(\"-----------------ctc_loss over-----------------\")\n",
    "    dataset_size = ds.get_dataset_size()\n",
    "    lr = Tensor(dynamic_lr(config, dataset_size), mstype.float32)\n",
    "    print(\"-----------------lr over-----------------\")\n",
    "    opt = mindspore.nn.RMSProp(params=net.trainable_params(),\n",
    "                               centered=True,\n",
    "                               learning_rate=lr,\n",
    "                               momentum=config.MOMENTUM,\n",
    "                               loss_scale=config.LOSS_SCALE)\n",
    "\n",
    "    net = WithLossCell(net, criterion)\n",
    "    print(\"-----------------with losscell over-----------------\")\n",
    "    if target == \"Ascend\":\n",
    "        loss_scale_manager = mindspore.train.loss_scale_manager.FixedLossScaleManager(\n",
    "            config.LOSS_SCALE, False)\n",
    "        net.set_train(True)\n",
    "        model = Model(net, optimizer=opt, loss_scale_manager=loss_scale_manager, amp_level=\"O2\")\n",
    "    else:\n",
    "        scaling_sens = Tensor(np.full((1), config.LOSS_SCALE), dtype=mstype.float32)\n",
    "        net = CNNCTCTrainOneStepWithLossScaleCell(net, opt, scaling_sens)\n",
    "        print(\"-----------------onestepwithlossscale over-----------------\")\n",
    "        net.set_train(True)\n",
    "        model = Model(net)\n",
    "\n",
    "    loss_cb = LossCallBack()\n",
    "    time_cb = TimeMonitor(data_size=dataset_size)\n",
    "    config_ck = CheckpointConfig(save_checkpoint_steps=config.SAVE_CKPT_PER_N_STEP,\n",
    "                                 keep_checkpoint_max=config.KEEP_CKPT_MAX_NUM)\n",
    "    ckpoint_cb = ModelCheckpoint(prefix=\"CNNCTC\", config=config_ck, directory=ckpt_save_dir)\n",
    "    callbacks = [loss_cb, time_cb, ckpoint_cb]\n",
    "\n",
    "    if config.run_distribute:\n",
    "        if device_id == 0:\n",
    "            model.train(config.TRAIN_EPOCHS,\n",
    "                        ds,\n",
    "                        callbacks=callbacks,\n",
    "                        dataset_sink_mode=False)\n",
    "        else:\n",
    "            callbacks.remove(ckpoint_cb)\n",
    "            model.train(config.TRAIN_EPOCHS, ds, callbacks=callbacks, dataset_sink_mode=False)\n",
    "    else:\n",
    "        model.train(config.TRAIN_EPOCHS,\n",
    "                    ds,\n",
    "                    callbacks=callbacks,\n",
    "                    dataset_sink_mode=False)\n",
    "\n",
    "#验证过程\n",
    "def test():\n",
    "    target = config.device_target\n",
    "    mindspore.set_context(device_target=target)\n",
    "    ds = GeneratorDataset(IIIT_Generator_batch, ['img', 'label_indices', 'text',\n",
    "                                                 'sequence_length', 'label_str'])\n",
    "    net = CNNCTC_Model(config.NUM_CLASS, config.HIDDEN_SIZE, config.FINAL_FEATURE_WIDTH)\n",
    "\n",
    "    ckpt_path = config.CHECKPOINT_PATH\n",
    "    param_dict = load_checkpoint(ckpt_path)\n",
    "    load_param_into_net(net, param_dict)\n",
    "    print('parameters loaded! from: ', ckpt_path)\n",
    "\n",
    "    converter = CTCLabelConverter(config.CHARACTER)\n",
    "\n",
    "    model_run_time = AverageMeter()\n",
    "    npu_to_cpu_time = AverageMeter()\n",
    "    postprocess_time = AverageMeter()\n",
    "\n",
    "    count = 0\n",
    "    correct_count = 0\n",
    "    for data in ds.create_tuple_iterator():\n",
    "        img, _, text, _, length = data\n",
    "\n",
    "        img_tensor = Tensor(img, mstype.float32)\n",
    "\n",
    "        model_run_begin = time.time()\n",
    "        model_predict = net(img_tensor)\n",
    "        model_run_end = time.time()\n",
    "        model_run_time.update(model_run_end - model_run_begin)\n",
    "\n",
    "        npu_to_cpu_begin = time.time()\n",
    "        model_predict = np.squeeze(model_predict.asnumpy())\n",
    "        npu_to_cpu_end = time.time()\n",
    "        npu_to_cpu_time.update(npu_to_cpu_end - npu_to_cpu_begin)\n",
    "\n",
    "        postprocess_begin = time.time()\n",
    "        preds_size = np.array([model_predict.shape[1]] * config.TEST_BATCH_SIZE)\n",
    "        preds_index = np.argmax(model_predict, 2)\n",
    "        preds_index = np.reshape(preds_index, [-1])\n",
    "        preds_str = converter.decode(preds_index, preds_size)\n",
    "        postprocess_end = time.time()\n",
    "        postprocess_time.update(postprocess_end - postprocess_begin)\n",
    "\n",
    "        label_str = converter.reverse_encode(text.asnumpy(), length.asnumpy())\n",
    "\n",
    "        if count == 0:\n",
    "            model_run_time.reset()\n",
    "            npu_to_cpu_time.reset()\n",
    "            postprocess_time.reset()\n",
    "        else:\n",
    "            print('---------model run time--------', model_run_time.avg)\n",
    "            print('---------npu_to_cpu run time--------', npu_to_cpu_time.avg)\n",
    "            print('---------postprocess run time--------', postprocess_time.avg)\n",
    "\n",
    "        print(\"Prediction samples: \\n\", preds_str[:5])\n",
    "        print(\"Ground truth: \\n\", label_str[:5])\n",
    "        for pred, label in zip(preds_str, label_str):\n",
    "            if pred == label:\n",
    "                correct_count += 1\n",
    "            count += 1\n",
    "\n",
    "    print('accuracy: ', correct_count / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行数据集处理，训练，验证流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "\n",
    "    print('###################dataset processing#######################')\n",
    "    print('Begin to combine multiple lmdb datasets')\n",
    "    #combine_lmdbs(['cnnctc_data/ST/', 'cnnctc_data/MJ/'], 'ST_MJ')\n",
    "    print('Begin to generate the index order of input data')\n",
    "    #combination = analyze_lmdb_label_length(\"ST_MJ\")\n",
    "    #generate_fix_shape_index_list('ST_MJ', combination,'st_mj_fixed_length_index_list.pkl')\n",
    "    print('###################dataset process done#######################')\n",
    "    print('###################start training #######################')\n",
    "    test()\n",
    "    print('###################end training #######################')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
